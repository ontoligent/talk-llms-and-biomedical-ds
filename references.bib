
@article{yang2022,
	title = {A Large Language Model for Electronic Health Records},
	author = {Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E. and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B. and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Harle, Christopher A. and Lipori, Gloria and Mitchell, Duane A. and Hogan, William R. and Shenkman, Elizabeth A. and Bian, Jiang and Wu, Yonghui},
	year = {2022},
	month = {12},
	date = {2022-12-26},
	journal = {npj Digital Medicine},
	pages = {1--9},
	volume = {5},
	number = {1},
	doi = {10.1038/s41746-022-00742-2},
	url = {https://www.nature.com/articles/s41746-022-00742-2},
	note = {Number: 1
Publisher: Nature Publishing Group},
	langid = {en}
}

@article{lim2023,
	title = {Artificial Intelligence for Health Message Generation: An Empirical Study Using a Large Language Model (llm) and Prompt Engineering},
	author = {Lim, Sue and {Schmälzle}, Ralf},
	year = {2023},
	date = {2023},
	journal = {Frontiers in Communication},
	volume = {8},
	url = {https://www.frontiersin.org/articles/10.3389/fcomm.2023.1129082}
}

@article{sallam2023,
	title = {ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns},
	author = {Sallam, Malik},
	year = {2023},
	month = {01},
	date = {2023-01},
	journal = {Healthcare},
	pages = {887},
	volume = {11},
	number = {6},
	doi = {10.3390/healthcare11060887},
	url = {https://www.mdpi.com/2227-9032/11/6/887},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	langid = {en}
}

@misc{salathé2023,
	title = {MEDITRON-70B: a new truly open AI model for medicine},
	author = {{Salathé}, Marcel},
	year = {2023},
	month = {11},
	date = {2023-11-28},
	url = {https://engineeringprompts.substack.com/p/meditron-70b-a-new-truly-open-ai}
}

@article{thirunavukarasu2023,
	title = {Large language models in medicine},
	author = {Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
	year = {2023},
	month = {08},
	date = {2023-08},
	journal = {Nature Medicine},
	pages = {1930--1940},
	volume = {29},
	number = {8},
	doi = {10.1038/s41591-023-02448-8},
	url = {https://www.nature.com/articles/s41591-023-02448-8},
	note = {Number: 8
Publisher: Nature Publishing Group},
	langid = {en}
}

@article{yadlowsky,
	title = {Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models},
	author = {Yadlowsky, Steve and Doshi, Lyric and Tripuraneni, Nilesh},
	doi = {10.48550/arXiv.2311.00871}
}

@article{singhal2023,
	title = {Large Language Models Encode Clinical Knowledge},
	author = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S. Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly, Chris and Babiker, Abubakr and {Schärli}, Nathanael and Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman, Dina and {Agüera y Arcas}, Blaise and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Chou, Katherine and Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar, Alvin and Barral, Joelle and Semturs, Christopher and Karthikesalingam, Alan and Natarajan, Vivek},
	year = {2023},
	month = {08},
	date = {2023-08},
	journal = {Nature},
	pages = {172--180},
	volume = {620},
	number = {7972},
	doi = {10.1038/s41586-023-06291-2},
	url = {https://www.nature.com/articles/s41586-023-06291-2},
	note = {Number: 7972
Publisher: Nature Publishing Group},
	langid = {en}
}

@misc{bolton2022,
	title = {Stanford CRFM Introduces PubMedGPT 2.7B},
	author = {Bolton, Elliot and Hall, David and Yasunaga, Michihiro and Lee, Tony and Manning, Chris and Liang, Percy},
	year = {2022},
	month = {12},
	date = {2022-12-15},
	url = {https://hai.stanford.edu/news/stanford-crfm-introduces-pubmedgpt-27b},
	langid = {en}
}

@article{nori,
	title = {Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine},
	author = {Nori, Harsha and Lee, Yin Tat and Zhang, Sheng and Carignan, Dean and Edgar, Richard and Fusi, Nicolo and King, Nicholas and Larson, Jonathan and Li, Yuanzhi and Liu, Weishung and Luo, Renqian and McKinney, Scott Mayer and Ness, Robert Osazuwa and Poon, Hoifung and Qin, Tao and Usuyama, Naoto and White, Chris and Horvitz, Eric},
	doi = {10.48550/arXiv.2311.16452}
}

@article{li,
	title = {From Beginner to Expert: Modeling Medical Knowledge into General LLMs},
	author = {Li, Qiang and Yang, Xiaoyan and Wang, Haowen and Wang, Qin and Liu, Lei and Wang, Junjie and Zhang, Yang and Chu, Mingyuan and Hu, Sen and Chen, Yicheng and Shen, Yue and Fan, Cong and Zhang, Wangshu and Xu, Teng and Gu, Jinjie and Zheng, Jing and Group, Guannan Zhang Ant},
	doi = {10.48550/arXiv.2312.01040}
}

@article{gu2022,
	title = {Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing},
	author = {Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
	year = {2022},
	month = {01},
	date = {2022-01-31},
	journal = {ACM Transactions on Computing for Healthcare},
	pages = {1--23},
	volume = {3},
	number = {1},
	doi = {10.1145/3458754},
	url = {http://arxiv.org/abs/2007.15779},
	note = {arXiv:2007.15779 [cs]}
}

@article{yang2022a,
	title = {A Large Language Model for Electronic Health Records},
	author = {Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E. and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B. and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Harle, Christopher A. and Lipori, Gloria and Mitchell, Duane A. and Hogan, William R. and Shenkman, Elizabeth A. and Bian, Jiang and Wu, Yonghui},
	year = {2022},
	month = {12},
	date = {2022-12-26},
	journal = {npj Digital Medicine},
	pages = {1--9},
	volume = {5},
	number = {1},
	doi = {10.1038/s41746-022-00742-2},
	url = {https://www.nature.com/articles/s41746-022-00742-2},
	note = {Number: 1
Publisher: Nature Publishing Group},
	langid = {en}
}

@article{shin,
	title = {BioMegatron: Larger Biomedical Domain Language Model},
	author = {Shin, Hoo-Chang and Zhang, Yang and Bakhturina, Evelina and Puri, Raul and Patwary, Mostofa and Shoeybi, Mohammad and Mani, Raghav},
	doi = {10.48550/arXiv.2010.06060}
}

@article{lee2020,
	title = {BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
	author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	year = {2020},
	month = {02},
	date = {2020-02-15},
	journal = {Bioinformatics},
	pages = {1234--1240},
	volume = {36},
	number = {4},
	doi = {10.1093/bioinformatics/btz682},
	url = {http://arxiv.org/abs/1901.08746},
	note = {arXiv:1901.08746 [cs]}
}

@misc{tian2023,
	title = {Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health},
	author = {Tian, Shubo and Jin, Qiao and Yeganova, Lana and Lai, Po-Ting and Zhu, Qingqing and Chen, Xiuying and Yang, Yifan and Chen, Qingyu and Kim, Won and Comeau, Donald C. and Islamaj, Rezarta and Kapoor, Aadit and Gao, Xin and Lu, Zhiyong},
	year = {2023},
	month = {06},
	date = {2023-06-15},
	url = {https://arxiv.org/abs/2306.10070v2},
	langid = {en}
}

@article{zhao,
	title = {A Survey of Large Language Models},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	doi = {10.48550/arXiv.2303.18223}
}

@misc{tian2023a,
	title = {Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health},
	author = {Tian, Shubo and Jin, Qiao and Yeganova, Lana and Lai, Po-Ting and Zhu, Qingqing and Chen, Xiuying and Yang, Yifan and Chen, Qingyu and Kim, Won and Comeau, Donald C. and Islamaj, Rezarta and Kapoor, Aadit and Gao, Xin and Lu, Zhiyong},
	year = {2023},
	month = {06},
	date = {2023-06-15},
	url = {https://arxiv.org/abs/2306.10070v2},
	langid = {en}
}

@article{alsentzer,
	title = {Publicly Available Clinical BERT Embeddings},
	author = {Alsentzer, Emily and Murphy, John R. and Boag, Willie and Weng, Wei-Hung and Jin, Di and Naumann, Tristan and McDermott, Matthew B. A.},
	doi = {10.48550/arXiv.1904.03323}
}

@article{shina,
	title = {BioMegatron: Larger Biomedical Domain Language Model},
	author = {Shin, Hoo-Chang and Zhang, Yang and Bakhturina, Evelina and Puri, Raul and Patwary, Mostofa and Shoeybi, Mohammad and Mani, Raghav},
	doi = {10.48550/arXiv.2010.06060}
}

@article{lee2020a,
	title = {BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
	author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	year = {2020},
	month = {02},
	date = {2020-02-15},
	journal = {Bioinformatics},
	pages = {1234--1240},
	volume = {36},
	number = {4},
	doi = {10.1093/bioinformatics/btz682},
	url = {http://arxiv.org/abs/1901.08746},
	note = {arXiv:1901.08746 [cs]}
}

@article{li2023,
	title = {Hi-BEHRT: Hierarchical Transformer-Based Model for Accurate Prediction of Clinical Events Using Multimodal Longitudinal Electronic Health Records},
	author = {Li, Yikuan and Mamouei, Mohammad and Salimi-Khorshidi, Gholamreza and Rao, Shishir and Hassaine, Abdelaali and Canoy, Dexter and Lukasiewicz, Thomas and Rahimi, Kazem},
	year = {2023},
	month = {02},
	date = {2023-02},
	journal = {IEEE journal of biomedical and health informatics},
	pages = {1106--1117},
	volume = {27},
	number = {2},
	doi = {10.1109/JBHI.2022.3224727},
	note = {PMID: 36427286
PMCID: PMC7615082},
	langid = {eng}
}

@article{pahune2023,
	title = {Several categories of Large Language Models (LLMs): A Short Survey},
	author = {Pahune, Saurabh and Chandrasekharan, Manoj},
	year = {2023},
	month = {07},
	date = {2023-07-31},
	journal = {International Journal for Research in Applied Science and Engineering Technology},
	pages = {615--633},
	volume = {11},
	number = {7},
	doi = {10.22214/ijraset.2023.54677},
	url = {http://arxiv.org/abs/2307.10188},
	note = {arXiv:2307.10188 [cs]}
}

@article{pahune2023a,
	title = {Several categories of Large Language Models (LLMs): A Short Survey},
	author = {Pahune, Saurabh and Chandrasekharan, Manoj},
	year = {2023},
	month = {07},
	date = {2023-07-31},
	journal = {International Journal for Research in Applied Science and Engineering Technology},
	pages = {615--633},
	volume = {11},
	number = {7},
	doi = {10.22214/ijraset.2023.54677},
	url = {http://arxiv.org/abs/2307.10188},
	note = {arXiv:2307.10188 [cs]}
}
