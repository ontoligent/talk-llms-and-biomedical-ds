# Notes

## Abstract

All branches of scientific knowledge are dually constituted as formally ordered bodies of knowledge and informally shared understandings of how things are done. Both forms are highly mediated through language and discourse, through the development of formal ontologies and vocabularies used to organize information and through informal modes of speech that characterize communication between members of a knowledge community. The deployment of Large Language Models (LLMs) in the context of biomedicine impacts both of these forms of language and knowledge as well as their relationship to each other. This talk will provide a framework for making sense of the changes that LLMs are having and are likely to have on biomedical knowledge, with special reference to biomedical data science education.

## Caveat

-   A prolegomonen to the use of LLMs as sources of knowledge.
-   Preliminary, Meta / synthetic ...

## Outline

-   The Question before us is: **How will LLMs affect biomedical data science education?**
    -   The mantra, "AI in the Loop: Humans in Charge," is inadequate. We want to know what the loop is and how it will be changed by the introduction of a new node. See [Stanford's HAI conference on this topic](https://hai.stanford.edu/events/2022-hai-fall-conference-ai-loop-humans-charge).
    -   'We want to know how LLMs will affect the production, distribution, and consumption of knowledge?
-   Background: What is an LLM?
-   Approach: **LLMs are discourse models**
    -   Rationalization effect: what is the relationship between language and knowledge?
        -   It's a question we have avoided since the invention of libraries.
    -   What is knowledge?
        -   CONSIDER BEGINNING WITH FEYNMAN

        -   It comes in two broad forms (Kant):

            -   [Analytic]{.underline}: Names and logical relations (logic)
            -   [Synthetic]{.underline}: Words and things ... Arrived at through experience and experimentation (but not purely; see *a priori* vs *a posteriori* synthetic statements)*.*
            -   Combinations: abstractions such as mass

        -   Point: knowledge requires situated interaction with the world (along with a mental model of the world).

            -   We call knowledge without this "book knowledge."

        -   This is similar to Richard Feynman's distinction between "knowing the name of something and knowing something," between knowing and understanding. See [this blog post](https://coffeeandjunk.com/knowing-something/).

            > You can know the name of a bird in all languages of the world, but when you're finished, you'll know absolutely nothing whatever about the bird. So let's look at the bird and what it's doing – that's what counts. I learned very early the difference between knowing the name of something and knowing something."

        -   Or, between knowledge and understanding – understanding involves assignment of certainty.

        -   Knowledge requires the referential function of language.
    -   What about LLMs?
        -   They lack this capacity — by design.
        -   This is because they are built on Zellig Harris' distributional hypothesis, which is an anti-referential theory of language.
        -   The word embeddings from which LLMs are built and further generate are operationalizations of this hypothesis.
            -   LLMs built from training data that are converted into embeddings and then fed to a transformer that applies an attention mechanism to generate more salient embeddings.
    -   More on Knowledge and Truth
        -   Knowledge K as Justified True Belief
        -   Truth T as correspondence, coherence, and pragmatist theories
        -   Model M and the separability of data and model
        -   Language – *langue* and *parole,* grammar and discourse
    -   LLMs are not language models per se – not models, since they violate the criterion of model separation; not grammars, since they have too many parameters. They are generative concordances. They are better thought of as discourse models. Discourse has always been messy for linguists.
    -   Evidence
        -   This explains their ability to shine at reproducing the forms of discourse, but often fail at producing truthful or logical outputs.
            -   They are truthful or logical to the extent that they are represent truthful and logical discourse in their training data.
        -   Perform very well within the bounds of the training data; they do not generalize [@yadlowsky]:
            -   "... \[LLMs\] have the remarkable ability to perform in-context learning (ICL) ... However when presented with tasks or functions which are out-of-domain of their pretraining data, we demonstrate various failure modes of transformers and degradation of their generalization for even simple extrapolation tasks. Together our results highlight **that the impressive ICL abilities of high-capacity sequence models may be more closely tied to the coverage of their pretraining data mixtures than inductive biases that create fundamental generalization capabilities**.
            -   ICL and the reproduction and hyper-coherence of the given ... May lead to the ossification of knowledge, i.e. scholasticism.
        -   They are not other minds, any more than the settlement patterns studied by archaeologists are.
-   Theory
    -   Viewing LLMs as discourse models allows us to represent their role in the "loop" more effectively.
    -   LLMs are agents that mediate communication.
    -   Thick mediation, communication, social AI
    -   Effects of media on social and psychological structures
    -   Study of discourse, discourse genres, codes
-   Application
    -   Discourse in the biomedical setting
        -   Two kinds of knowledge transmission
            -   Formal
            -   Informal
    -   LLMs in biomedicine roughly follow these paths
        -   Type 1
            -   Data sources: PubMed abstracts and essays, the Pile
            -   Models: Meditron, BioBERT, PubMedBERT, PubMedGPT
            -   Use cases (tasks): MQA, MRE, NER
        -   Type 2
            -   Data Sources: Clinical notes, records from diagnoses, medications, hospital procedures, general practice (GP) tests, BP measurements (both systolic and diastolic pressure), drinking status, smoking status, and BMI.
                -   Discuss EMR and EHR
            -   Models: GatorTron, Hi-BEHRT, MedNLI
            -   Use cases: summarization, doctor patient communication, etc., inference
    -   Most effort is focused on Type 1 but Type 2 is likely to have more of an impact since it is at point of delivery and where the reception of DS and AI in biomedicine has been resistant.
        -   "It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured electronic health records (EHRs) within the current legal and ethical framework while ensuring privacy of patient information and accuracy of the information provided" [@pahune2023a: 19].
-   Effects
    -   Computational sublimation, reproduction of knowledge, databasing of knowledge
    -   ICL and hypercoherence
    -   Practices change in order to accommodate measurement requirements of data products, e.g. with Hi-BEHRT and frequency requirements of other EHR modalities.d

## Dimensions

Studies of large language models in the context of medicine usually focus on one of three dimensions:

-   Data used to fine-tune language models
-   Language models themselves, along with performance measures at various generic tasks
-   Use cases for language models

The first and third can be broken down into discourse genres and communicative situations. For example patient records, or medical research literature as data input, and improving medical research or summarizing doctor's notes, or generating messages to patients as data output.

## Examples and Exhibits

**Prompt engineering as exemplary of planning vs situated action.**

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10585440/

This paper summarizes the current state of research about prompt engineering and, at the same time, aims at providing practical recommendations for the wide range of health care professionals to improve their interactions with LLMs.

Compare data sources for each of the emerging language models

How are models used? See use cases. How much planning?

Convert patient conversations https://techcrunch.com/2023/03/14/nabla-a-french-digital-health-startup-launches-copilot-using-gpt-3-to-turn-patient-conversations-into-actionable-items/

Diagnosis https://www.statnews.com/2023/02/13/chatgpt-assisted-diagnosis/

Automating repetitive functions https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00021-3/fulltext this Lancet piece on the future of discharge summaries.

Scientific research https://www.mdpi.com/2227-9032/11/6/887

Generate health awareness messages https://www.frontiersin.org/articles/10.3389/fcomm.2023.1129082

Info retrieval and decision support https://provectus.com/blog/comparison-large-language-models-biomedical-domain/

## Tasks

Broad categories seem to be: retrieval, generation, synthesis

-   BIR: Biomedical information retrieval (seems general)

    -   MTS: Medical text summarization (aka Biomedical Text Summarization), e.g. literature summarization, radiology report summarization, and clinical note summarization

-   STS: Semantic Text Similarity; determine the extent to which two sentences are similar in terms of semantic meaning.

-   Information extraction

    -   NER: Named Entity Recognition for clinical concept extraction

    -   MRE: medical relation extraction, e.g chemical interaction, drug interaction, and gene-disease association; essentially a sequence classification task, classifying a set of sentences into a category.

-   NLI: natural language inference; determine whether a conclusion can be inferred from a given sentence

-   MQA: medical question answering; a complex clinical NLP task that requires understanding information from the entire document.

-   MMG: medical message generation

-   Medical reasoning (NLI?)

-   Medical conversations

-   PICO Evidence-Based Medical Information Extraction

-   DC Document Classification

-   TGT: Text generation tasks (this is a broad category)

-   Risk Prediction (See EHR and Hi-BEHRT)

## Document Types

-   General
    -   Wiikipedia
    -   The Pile
    -   RealNews
-   Domain specific
    -   Research papers and abstracts
    -   Clinical notes
    -   EHR Electronic health records. "represent a holistic overview of patients’ trajectories"
        -   Records from diagnoses, medications, hospital procedures, general practice (GP) tests, BP measurements (both systolic and diastolic pressure), drinking status, smoking status, and BMI

## Models

See [@pahune2023] for a comprehensive list of models, datasets, and tasks.

+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Model             | Data / Source                                                                                                                                                                                               | Uses                                                                  |                                                                                                                                            |
+===================+=============================================================================================================================================================================================================+=======================================================================+============================================================================================================================================+
| Meditron          | Abstracts and papers\                                                                                                                                                                                       |                                                                       | [@salathé2023]                                                                                                                             |
|                   | Clinical guidelines                                                                                                                                                                                         |                                                                       |                                                                                                                                            |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Gatortron         | Clinical notes (from UFH), Wikipedia, and PubMed                                                                                                                                                            | NER, MRE, STS, NLI, MQA                                               | [@yang2022]                                                                                                                                |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| BioBERT           | Citations, abstracts, articles from PubMed and PMC.                                                                                                                                                         | NER, MRE, MQA, etc.                                                   | [Repo](https://github.com/dmis-lab/biobert) [Article](https://towardsdatascience.com/tagging-genes-and-proteins-with-biobert-c7b04fc6eb4f) |
|                   |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
|                   |                                                                                                                                                                                                             |                                                                       | <https://github.com/naver/biobert-pretrained>                                                                                              |
|                   |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
|                   |                                                                                                                                                                                                             |                                                                       | [@lee2020]                                                                                                                                 |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| PubMedBERT        | Pretrained language models from scratch; PubMed abstracts and full text (PMC)                                                                                                                               | NER, PICO, MRE, STS, DC, MQA                                          | [@gu2022]                                                                                                                                  |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| PubMedGPT         | Biomedical abstracts and papers; [the Pile](https://pile.eleuther.ai/)                                                                                                                                      | MQA                                                                   | [HAI Paper](https://hai.stanford.edu/news/stanford-crfm-introduces-pubmedgpt-27b)                                                          |
|                   |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
|                   |                                                                                                                                                                                                             |                                                                       | [@bolton2022]                                                                                                                              |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| BioMegatron       | Wikipedia, CC-Stories, RealNews, and OpenWebtext + PubMed abstracts, PMC full-text corpus                                                                                                                   | NER, MRE, MQA                                                         | [@shin]                                                                                                                                    |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| ClinicalBERT      |                                                                                                                                                                                                             |                                                                       | [@alsentzer]                                                                                                                               |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| BioBERT           | PubMed, PMC                                                                                                                                                                                                 | NER, MRE, MQA                                                         | [@lee2020a]                                                                                                                                |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| BLOOM             | GPT-3                                                                                                                                                                                                       | MMG                                                                   | [@lim2023]                                                                                                                                 |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| BioGPT            |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Flan-PaLM,\       | A large language model from Google Research, designed for the medical domain; trained on medical exams, medical research, and consumer queries                                                              | MQA                                                                   | [@singhal2023]\                                                                                                                            |
| Med-PaLM,\        |                                                                                                                                                                                                             |                                                                       | <https://sites.research.google/med-palm/>                                                                                                  |
| MedLM             |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Clinical Camel    |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Medprompt (GPT-4) | GPT4 + "based on a composition of several prompting strategies"                                                                                                                                             | MQA                                                                   | [@nori]                                                                                                                                    |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Palmyra-Med       | "a custom-curated medical dataset of 200,000 examples"                                                                                                                                                      | MQA                                                                   | <https://dev.writer.com/docs/palmyra-med-instruction-based-fine-tuning-of-llms-enhancing-medical-domain-performance>                       |
|                   |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
|                   | The Pile, RefinedWeb                                                                                                                                                                                        |                                                                       |                                                                                                                                            |
|                   |                                                                                                                                                                                                             |                                                                       |                                                                                                                                            |
|                   | PubMedQA and MedQA for fine tuning                                                                                                                                                                          |                                                                       |                                                                                                                                            |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| AntGLM-Med        |                                                                                                                                                                                                             | MQA, multiple choice answer, medical reasoning, medical conversations | [@li]                                                                                                                                      |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Hi-BEHRT          | EHR; "We included records from diagnoses, medications, hospital procedures, general practice (GP) tests, BP measurements (both systolic and diastolic pressure), drinking status, smoking status, and BMI." |                                                                       | [@li2023]                                                                                                                                  |
+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+

## Benchmark Datasets

See <https://dl.acm.org/doi/10.1145/3458754> for more.

+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+
| MultiMedQA | "a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA"                                                                                                                                                                                                                                                 | Clinical knowledge | [@thirunavukarasu2023]             |
|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    |                                    |
|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    | [@singhal2023]                     |
+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+
| MedQA      |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    | <https://github.com/jind11/MedQA>  |
+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+
| PubMedQA   |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    | <https://pubmedqa.github.io/>      |
+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+
| BioASQ     |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    | <http://bioasq.org/>               |
+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+
| BIOSSES    | The Sentence Similarity Estimation System for the Biomedical Domain \[54\] contains 100 pairs of PubMed sentences each of which is annotated by five expert-level annotators with an estimated similarity score in the range from 0 (no relation) to 4 (equivalent meanings). It is a regression task, with the average score as the final annotation. We use the same train/dev/test split in Peng et al. \[45\] and use Pearson correlation for evaluation. |                    |                                    |
+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+
| MedNLI     | We introduce MedNLI - a dataset annotated by doctors, performing a natural language inference task), grounded in the medical history of patients. We present strategies to: 1) leverage transfer learning using datasets from the open domain, (e.g. SNLI) and 2) incorporate domain knowledge from external data and lexical sources (e.g. medical terminologies). Our results demonstrate performance gains using both strategies.                          |                    | <https://jgc128.github.io/mednli/> |
|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    |                                    |
|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                    | <https://github.com/jgc128/mednli> |
+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------+

## Images

### Meditron

![MEDITRON’s performance on the medical benchmark MedQA. [Source](https://engineeringprompts.substack.com/p/meditron-70b-a-new-truly-open-ai).](images/paste-1.png){style="border: 1px solid black;"}

![](images/paste-2.png){style="border: 1px solid black;"}

[GitHub Repo](https://github.com/epfLLM/meditron)

## LLMs in General

[@zhao] Very good overview of LLM technology. Lots of good images.

[@tian2023a] Very good overview of LLMs in biomedicine.

## Notes

"Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health" [@tian2023]

Very good overview of LLMs in general.

> Following an extensive literature survey, we find that significant advances have been made in the field of text generation tasks, surpassing the previous state-of-the-art methods. For other applications, the advances have been modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid progress indicates that such methods hold great potential to provide valuable means for accelerating discovery and improving health. We also find that the use of LLMs, like ChatGPT, in the fields of biomedicine and health entails various risks and challenges, including fabricated information in its generated responses, as well as legal and privacy concerns associated with sensitive patient data. We believe this survey can provide a comprehensive and timely overview to biomedical researchers and healthcare practitioners on the opportunities and challenges associated with using ChatGPT and other LLMs for transforming biomedicine and health.

### Graph

```{dot}
digraph G {

    rankdir=BT
    node [shape=parallelogram]

    // Events
    PT [label="Pre-training\n(from scratch)"]
    FT [label="Fine-tuning\n(transfer)"]
    RL [label="RLHF with PPO\n(alignment)"]
    US [label="Usage\nevents"]

    // Agents
    node[shape=oval]
    U [label="User"]

    // Data sources
    node [shape=folder]
    D1 [label="General\ncorpus data"]
    D2 [label="Domain specific\nor augmented\ncorpus data"]
    HA [label="Human\nannotations"]

    // Models
    node [shape=circle]
    M1
    M2
    RM [label="Reward\nModel"]
    LLM 
  

    // Flowchart
    PT -> M1 -> FT -> M2 -> RL -> LLM
    RM -> RL 
    RL -> RM
    D1 -> PT
    D2 -> FT
    LLM -> US
    U -> US [label="prompt"]
    US -> U [label="response"]
 

    // Alignments
    node[style="invis"]
    edge[style="invis"]
    1  -> 2 -> 3 -> 4 -> 5 -> 6 -> 7
    {rank=same; 1; PT; D1 }
    {rank=same; 2; M1; }
    {rank=same; 3; FT; D2;}
    {rank=same; 4; M2; }
    {rank=same; 5; RL; RM; HA }
    {rank=same; 6; LLM;}
    {rank=same; 7; US; U; }
 
}
```

RLHF: Reinforcement Learning with Human Feedback.

PPO: Proximal Policy Optimization (see [HugginFace article](https://www.diigo.com/user/ontoligent/b/652970529?ann_md5=eb6c19129e9ad3eac74916243b3f5491) on its role and [this](https://huggingface.co/blog/deep-rl-ppo) for more detail). "The idea with Proximal Policy Optimization (PPO) is that we want to improve the training stability of the policy by limiting the change you make to the policy at each training epoch: we want to avoid having too large policy updates." [Source](https://diigo.com/0uwkrh).

![](images/paste-3.png)

------------------------------------------------------------------------

"ChatGPT Utility in Healthcare Education,Research, and Practice: Systematic Review on the Promising Perspectivesand Valid Concerns" [@sallam2023]

Review of literature related to the application of ChatGPT to medicine. Provides a comprehensive classified list of papers in table form.

> Categorization of the benefits/applications of ChatGPT was as follows: (1) educational benefits in health care education (e.g., generation of realistic and variable clinical vignettes, customized clinical cases with immediate feedback based on the student’s needs, enhanced communications skills); (2) benefits in academic/scientific writing (e.g., text generation, summarization, translation, and literature review in scientific research); (3) benefits in scientific research (e.g., efficient analysis of large datasets, drug discovery, identification of potential drug targets, generation of codes in scientific research); (4) benefits in health care practice (e.g., improvements in personalized medicine, diagnosis, treatment, lifestyle recommendations based on personalized traits, documentation/generation of reports); and (5) being a freely available package.
>
> \(4\)